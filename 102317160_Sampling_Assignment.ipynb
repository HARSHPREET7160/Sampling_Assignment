{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8ZVD4tugFk",
        "outputId": "b6d77b17-2d86-48fd-b2aa-e03fd2ba07a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"SAMPLING ASSIGNMENT\\n\")\n",
        "\n",
        "#LOAD DATA\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"\\nOriginal Class Distribution:\")\n",
        "print(df['Class'].value_counts())\n",
        "\n",
        "#BALANCE DATA\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
        "\n",
        "X_bal_df = pd.DataFrame(X_balanced)\n",
        "y_bal_series = pd.Series(y_balanced)\n",
        "\n",
        "print(\"\\nBalanced Class Distribution:\")\n",
        "print(y_bal_series.value_counts())\n",
        "\n",
        "#SAMPLE SIZE\n",
        "Z = 1.96\n",
        "p = 0.5\n",
        "E = 0.05\n",
        "n = int((Z**2 * p * (1-p)) / E**2)\n",
        "\n",
        "sample_size = min(n, len(X_bal_df))\n",
        "print(\"\\nSample Size:\", sample_size)\n",
        "\n",
        "dataset = pd.concat([X_bal_df, y_bal_series.rename(\"Class\")], axis=1)\n",
        "\n",
        "samples = {}\n",
        "\n",
        "# 1. Simple Random Sampling\n",
        "samples[\"Sample1\"] = dataset.sample(n=sample_size, random_state=42)\n",
        "\n",
        "# 2. Systematic Sampling\n",
        "step = max(1, len(dataset)//sample_size)\n",
        "samples[\"Sample2\"] = dataset.iloc[::step].head(sample_size)\n",
        "\n",
        "# 3. Stratified Sampling\n",
        "_, stratified = train_test_split(dataset,\n",
        "                                 test_size=sample_size/len(dataset),\n",
        "                                 stratify=dataset[\"Class\"],\n",
        "                                 random_state=42)\n",
        "samples[\"Sample3\"] = stratified\n",
        "\n",
        "# 4. Cluster Sampling (true cluster sampling)\n",
        "dataset[\"Cluster\"] = pd.cut(dataset.index, bins=10, labels=False)\n",
        "chosen_clusters = np.random.choice(dataset[\"Cluster\"].unique(), size=3, replace=False)\n",
        "cluster_sample = dataset[dataset[\"Cluster\"].isin(chosen_clusters)]\n",
        "samples[\"Sample4\"] = cluster_sample.drop(\"Cluster\", axis=1).sample(n=sample_size, random_state=42)\n",
        "\n",
        "# 5. Bootstrap Sampling\n",
        "samples[\"Sample5\"] = dataset.sample(n=sample_size, replace=True, random_state=42)\n",
        "\n",
        "print(\"\\nSamples Created Successfully\")\n",
        "\n",
        "#MODELS\n",
        "models = {\n",
        "    \"M1\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
        "    \"M2\": DecisionTreeClassifier(max_depth=10, random_state=42),\n",
        "    \"M3\": RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42),\n",
        "    \"M4\": SVC(kernel='linear', random_state=42),\n",
        "    \"M5\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "#TRAIN & EVALUATE\n",
        "results = {}\n",
        "\n",
        "for sample_name, sample_data in samples.items():\n",
        "    X_s = sample_data.drop(\"Class\", axis=1)\n",
        "    y_s = sample_data[\"Class\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_s, y_s, test_size=0.3, random_state=42, stratify=y_s\n",
        "    )\n",
        "\n",
        "    results[sample_name] = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = round(accuracy_score(y_test, y_pred)*100, 2)\n",
        "        results[sample_name][model_name] = acc\n",
        "        print(f\"{sample_name} - {model_name}: {acc}%\")\n",
        "\n",
        "#RESULT TABLE\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"FINAL ACCURACY TABLE (%)\")\n",
        "print(results_df)\n",
        "\n",
        "#BEST COMBINATIONS\n",
        "print(\"\\nBEST SAMPLING FOR EACH MODEL\")\n",
        "for model in results_df.columns:\n",
        "    best_sample = results_df[model].idxmax()\n",
        "    print(f\"{model} -> {best_sample} ({results_df[model].max()}%)\")\n",
        "\n",
        "print(\"\\nBEST MODEL FOR EACH SAMPLING\")\n",
        "for sample in results_df.index:\n",
        "    best_model = results_df.loc[sample].idxmax()\n",
        "    print(f\"{sample} -> {best_model} ({results_df.loc[sample].max()}%)\")\n",
        "\n",
        "# Save CSV\n",
        "results_df.to_csv(\"sampling_results.csv\")\n",
        "print(\"\\nResults saved as sampling_results.csv\")\n",
        "\n",
        "print(\"\\nASSIGNMENT COMPLETED SUCCESSFULLY\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yWJanwRuhgM",
        "outputId": "616419ce-1ba2-4c70-8489-127438ec61c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLING ASSIGNMENT\n",
            "\n",
            "\n",
            "Original Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample Size: 384\n",
            "\n",
            "Samples Created Successfully\n",
            "Sample1 - M1: 87.07%\n",
            "Sample1 - M2: 96.55%\n",
            "Sample1 - M3: 100.0%\n",
            "Sample1 - M4: 87.07%\n",
            "Sample1 - M5: 90.52%\n",
            "Sample2 - M1: 87.07%\n",
            "Sample2 - M2: 97.41%\n",
            "Sample2 - M3: 100.0%\n",
            "Sample2 - M4: 85.34%\n",
            "Sample2 - M5: 95.69%\n",
            "Sample3 - M1: 92.24%\n",
            "Sample3 - M2: 98.28%\n",
            "Sample3 - M3: 100.0%\n",
            "Sample3 - M4: 93.1%\n",
            "Sample3 - M5: 93.97%\n",
            "Sample4 - M1: 92.24%\n",
            "Sample4 - M2: 96.55%\n",
            "Sample4 - M3: 98.28%\n",
            "Sample4 - M4: 94.83%\n",
            "Sample4 - M5: 96.55%\n",
            "Sample5 - M1: 98.28%\n",
            "Sample5 - M2: 97.41%\n",
            "Sample5 - M3: 98.28%\n",
            "Sample5 - M4: 98.28%\n",
            "Sample5 - M5: 96.55%\n",
            "FINAL ACCURACY TABLE (%)\n",
            "            M1     M2      M3     M4     M5\n",
            "Sample1  87.07  96.55  100.00  87.07  90.52\n",
            "Sample2  87.07  97.41  100.00  85.34  95.69\n",
            "Sample3  92.24  98.28  100.00  93.10  93.97\n",
            "Sample4  92.24  96.55   98.28  94.83  96.55\n",
            "Sample5  98.28  97.41   98.28  98.28  96.55\n",
            "\n",
            "BEST SAMPLING FOR EACH MODEL\n",
            "M1 -> Sample5 (98.28%)\n",
            "M2 -> Sample3 (98.28%)\n",
            "M3 -> Sample1 (100.0%)\n",
            "M4 -> Sample5 (98.28%)\n",
            "M5 -> Sample4 (96.55%)\n",
            "\n",
            "BEST MODEL FOR EACH SAMPLING\n",
            "Sample1 -> M3 (100.0%)\n",
            "Sample2 -> M3 (100.0%)\n",
            "Sample3 -> M3 (100.0%)\n",
            "Sample4 -> M3 (98.28%)\n",
            "Sample5 -> M1 (98.28%)\n",
            "\n",
            "Results saved as sampling_results.csv\n",
            "\n",
            "ASSIGNMENT COMPLETED SUCCESSFULLY\n"
          ]
        }
      ]
    }
  ]
}